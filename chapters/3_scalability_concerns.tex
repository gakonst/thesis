\chapter{Blockchain Scalability}

\section{Bottlenecks in Scalability}
A blockchain's ability to scale is often measured by the amount of transactions it can verify per second. A block gets appended to the Ethereum blockchain every 12.5 seconds on average, and can contain only a finite amount of transactions. As a result, transaction throughput is bound by the frequency of new blocks and by the number of transactions in them.

We argue that there are two levels of scalability, scalability on contract and on network level. Better contract design can result in transactions which require less gas to execute, and thus allow for more transactions to fit in a block while also making it cheaper for the end user. It should be noted that as Ethereum's current blockGasLimit is set by the miners at 8003916; if all transactions in Ethereum were simple financial transactions\footnote{Not calls to smart contracts. Transactions without any extra data cost 21000 gas}, each block would be able to verify ~381 transactions - 25 transactions per second (tps) - which is still not comparable to traditional payment operators. 

\section{Network Level Scalability}
Scale should not be confused with scalability. While scale describes the size of a system and the amount of data being processed, scalability describes how the cost of running the system changes as scale increases. Existing blockchains scale poorly due to the costs associated with them increase faster than the rate at which data can be processed. 

First of all, transactions per second as a metric is innacurate. Solving scalability does not imply just increasing the transaction throughput. It is a constraint-satisfaction-problem; the goal is to maximize throughput while maintaining the network's decentralization and security. 

\begin{figure}[H]
\begin{quote}
    \textbf{This sounds like thereâ€™s some kind of scalability trilemma at play. What is this trilemma and can we break through it?}

    The trilemma claims that blockchain systems can only at most have two of the following three properties:

    \begin{itemize}
        \item Decentralization (defined as the system being able to run in a scenario where each participant only has access to $O(c)$ resources, ie. a regular laptop or small VPS)
        \item Scalability (defined as being able to process $O(n) > O(c)$ transactions)
        \item Security (defined as being secure against attackers with up to $O(n)$ resources)
    \end{itemize}
\end{quote}
\label{fig:trilemma}
\caption{The Scalability Trilemma, from Ethereum's Sharding documentation \cite{sharding}}
\end{figure}

As an example that trades decentralization for more transactions is the increase of block size. Increasing the size of each block, implies more disk space for storing the blockchain, better bandwith for propagating the blocks and more processing power on a node to verify any performed computations. This eventually requires computers with datacenter-level network connections and processing power which are not accessible to the average consumer, thus damaging decentralization which is the core value proposition of blockchain. % The blockGasLimit can be voted on by miners\footnote{\url{https://www.etherchain.org/tools/gasLimitVoting}}. % In addition to the reasons stated above, increasing the gas limit also potentially damages the security of the network due to increased uncle rates, Ethereum's analog to Bitcoin's orphan blocks \footnote{\url{https://blockchain.info/orphaned-blocks}}. Longer propagation time implies that a miner will spend more time searching for a solution until they receive a valid block, and thus has more chances of finding a valid block in that time. As a result, 

As described in \cite{scaling-trustless-models}, Proof of Work is a consensus algorithm optimized for censorship-resistance while (in theory) maintain a low barrier to entry. In reality, due to economies of scale, PoW blockchains end up being centralized around small numbers of miners \cite{Gencer2018DecentralizationIB}. 

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{scalability_triangle_pow}
    \caption{Bitcoin and Ethereum's PoW networks have slow probabilistic time to finality and do not scale well. Mining capacity has high concentration in a small amount of entities, from \cite{scaling-trustless-models}}
    \label{fig:scalability_triangle_pow}
\end{figure}

We proceed to discuss some network level solutions that can improve Ethereum's scalability.

\subsubsection{Proof-of-Stake}
Proof-of-Stake (PoS) is an alternative consensus algorithm where in the place of miners, there are validators who instead of expending computational resources to `mine' a valid block, they stake\footnote{Lock up for an amount of time} their ether and the probability for them to be elected to validate the next block is proportional to their stake. Designing a secure PoS protocol is still under heavy research. The Ethereum Foundation is working on `Casper the Friendly Finality Gadget'\cite{casperffg} which is a hybrid PoW/PoS consensus algorithm that provides block finality\footnote{A block that is finalized cannot be reverted. This is different to traditional PoW which achieves \textit{probabilistic finality}; a block is considered harder to revert the older it is} which combined with the `correct-by-construction Casper the Friendly GHOST'\footnote{Uses the GHOST protocol to choose a chain in the case of a fork.} \cite{caspertfg} will enable a full transition to Proof of Stake. 

\subsubsection{Sidechains}
A sidechain \cite{sidechains} is a blockchain defined by a custom `rule-set' and can be used to offload computations from another chain. Individual sidechains can follow different sets of rules from the mainchain, which means they can optimize for applications that require high speeds or heavy computation, while still relying on the mainchain for issues requiring the highest levels of security. Ethereum's sidechain solution is called `Plasma' \cite{plasma} and involves creating `child-chains' that run their own consensus algorithm with a two-way peg as described in \cite{sidechains}. \textit{Plasma chains} can have more adjustable parameters such as be less decentralized, however the protocol does not allow for the child-chain operator to abuse their power. A more recent Plasma construct is called `Plasma-Cash' \cite{plasmacash} and describes a more efficient way of executing fraud proofs, in the case of a malicious actor in a \textit{Plasma chain}.

\subsubsection{Sharding}
Due to the architecture of the EVM all transactions are executed sequentially on all ethereum nodes. Sharding refers to splitting the process across nodes, so that each full node is responsible only for a shard\footnote{A shard is a part of the blockchain's state} and acts as a light client to the other shards. Sharding is the most complex scaling solution and is still at research stages. It also requires a stable Proof of Stake consensus algorithm to function properly.

\subsubsection{State channels}
Contrary to the previous solutions which still record messages on a blockchain, state channels involves exchange of information `off-chain'. The primary use-case for state channels is micro-transactions between two or more parties. This technique involves exchanging signed messages through a secure communications channel and perform a transaction on the blockchain only when the process is done\footnote{Example: Instead of making 10 transactions worth 0.1 ether each, a transaction is made to open the channel, participants exchange off-chain messages transferring value, and settle or dispute the channel with one more transaction at the end.}.
    
\section{Contract Level Scalability}
In a recent study \cite{DBLP:journals/corr/ChenLLZ17}, after evaluating 4240 smart contracts, it is found that over 70\% of them are under-optimized with respect to gas from the compiler. In this section we explore how gas gets computed in smart contracts and ways we can save on gas and transaction costs.


\subsection{Gas Costs}
An Ethereum transaction's gas costs are split in: % https://ethereum.stackexchange.com/a/29560
\begin{enumerate}
    \item \textbf{Transaction Costs:} The cost of sending data to the blockchain. There are 4 items which make up the full transaction cost:
        \begin{enumerate}
            \item The base cost of a transaction (21000 gas)
            \item The cost of a contract deployment (32000 gas)
            \item The cost for every zero byte of data in a transaction's input (4 gas per zero byte).
            \item The cost of every non-zero byte of data in a transaction's input (68 gas per zero byte)
        \end{enumerate}
    \item \textbf{Execution Costs:} The cost of computational operations which are executed as a result of the the transaction, as described in detail in \cite{ethereum, gas} 
\end{enumerate} 

Gas costs get translated to transaction fees. As a result, a contract should be designed to minimize its operational gas costs in order to minimize its transaction fees. In addition, as gas is a unit for computational costs, less gas consumed results in less burden on the nodes validating the smart contracts which can lead to better scalability.

\input{tables/opcode_table.tex}

% bytecontracts includes constructor and general initialisation contracts which is not needed anymore at runtime. The contracts that is sent during deployment (bytecontracts), even excluding the constructor arguments, is - in general - different from the contracts that is stored at that address (the runtimeBytecontracts).

As seen in Table \ref{table:opcode_table}, the most expensive operations involve CREATE\footnote{Used to create a new contract.} and SSTORE operations. The focus of this section will be to explore ways to decrease gas costs on Smart Contracts, either through better practices or by handcrafting optimizations for specific use cases.

It should be noted, that non-standard methods have been proposed for reducing fees incurred by gas costs. A recent construction \cite{gastoken} describes a method of buying gas at low cost periods and saving it in order to spend it when gas prices are higher\footnote{When the network is congested}. The economic implications of gas arbitrage are outside the scope of this Master Thesis. 

General rules that should be followed for saving gas costs:
\begin{enumerate}
    \item Enable compiler optimizations (although can lead to unexpected scenarios~\cite{compiler}).
    \item Reuse code through libraries~\cite{library}.
    \item Setting a variable back to zero refunds 15000 gas through SSTORE, so if a variable is going to be unused it is considered good practice to call `delete' on it. 
    \item Use `bytes32' instead of `string' for strings that are of known size. `bytes32' always fit in an EVM word, while `string' types can be arbitrarily long and thus require more gas for saving their length.
    \item Do not store large amounts of data on a blockchain. It is more efficient to store a hash which can be either proof of the existence of the data at a point in time, or it can be a hash pointing to the full data\footnote{This pattern has been used in combination with IPFS, \url{https://ipfs.io}}
\end{enumerate}

As described in \cite{DBLP:journals/corr/ChenLLZ17} there is a lot of room for further compiler optimizations. Future Solidity compiler versions are addressing some already\footnote{\url{https://github.com/ethereum/solidity/issues/3760}}\footnote{\url{https://github.com/ethereum/solidity/issues/3716}}\footnote{\url{https://github.com/ethereum/solidity/issues/3691}}

The EVM operates on 32 byte (256 bit) words. The compiler is able to `tightly pack' data together, which means that 2 128 bit storage variables can be efficiently stored with 1 SSTORE command. The \textit{optimize} flag of the Solidity compiler needs to be activated to access this feature when programming in Solidity.

\subsection{Gas Savings Case Study}
In order to illustrate our findings and compare across different scenarios, we will perform a Solidity benchmarking test based on a use-case of a Solidity Smart Contract which describes a game. The contract-design requirements are: 
\begin{itemize}
    \item A user must be able to register.
    \item A user must be able to create a character with certain traits as function arguments.
    \item A user must be able to retrieve the traits of a character.
\end{itemize}

\input{tables/character.tex}


The size of the variables is selected so that all the information required to describe a `Character' can fit in a 256 bit word. The interface that satisfies the requirements is shown in~\ref{fig:game_interface}

For each of the following implementations we will examine the deployment gas costs, as well as the gas costs for calling the `CreateCharacter' function:

\begin{enumerate}
    \item Tightly packed structures for setting data
    \item Bit masking encoding for setting data
    \item Bit masking encoding utilizing libraries, influenced by \cite{virtualstruct}.
\end{enumerate}

%% TODO Make contracts appear in some good way. 2 columns, each one for Create/Get character.
The full contracts of each contract can be found in the Appendix. In this section we describe the implementation and in section \label{results} we go over the results and caveats of each method.

\subsubsection{Method 1: Tight packing of variables through structs} \label{method1}
We're using a solidity `struct'\footnote{\url{http://solidity.readthedocs.io/en/v0.4.21/types.html}} as a means to group all traits of a character as described in \ref{table:characteristics}. This allows for easy code readability since every variable of a struct object can be accessed by its name as seen in \ref{fig:struct_optimization:c}, like the property of an object. 

In this case, assignment and retrieval of the variables is done in a very straightforward way. By utilizing Solidity's built-in structures and arrays, we can create an array of `Character' type structures and access their traits by their indexes, as done in \ref{fig:struct_optimization:c}

The gas costs per function call with this method are: 
\input{tables/GameTightlyPacked.sol_data.tex}

\subsubsection{Method 2: Manually pack variables in a 256 bit uint with masking and shifting} \label{method2}
In \ref{method1} we let the compiler perform optimizations in order to make storing the data more efficient. It turns out\footnote{\url{https://github.com/figs999/Ethereum/blob/master/Solc.aComedyInOneAct}} that even with the optimizer, a lot of redundant operations are done. In order to get better results, we create a `virtual struct' by encoding all the information needed in a `uint' variable 
Here we create a new character by shifting variables. Essentially, instead of creating a `struct' as Solidity expects it and let the compiler do the parsing, we do it ourselves. That way, we achieve gas costs which are substantially lower.

The encoding is done by shifting each of the described variables and then performing bitwise OR operations so that the data gets embedded in the uint variable, as shown in \ref{fig:uint_encoding}. This is implemented in \ref{fig:uint_encoding_code}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{uint_encoding}
    \caption{Setting data requires shifting left $N$ times and performing bitwise OR with the target variable, where $N$ is the number of bits of the previous variable.}
    \label{fig:uint_encoding}
\end{figure}


Retrieving the data requires shifting the `Character' uint and performing bitwise `AND' operations in order to mask out the higher bits of the variable that are unused, as shown in \ref{fig:uint_decoding}, implementation in \ref{fig:uint_decoding_code}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{uint_decoding}
    \caption{Decoding shift and}
    \label{fig:uint_decoding}
\end{figure}


The gas costs per function call with this method are: 
\input{tables/GameByteMasking.sol_data.tex}

\subsubsection{Method 3: Manually pack variables in a 32 byte variable with masking and shifting, utilizing Solidity Libraries} \label{method3}

Code reusability and readability should always be given high priority. In the previous method, although the data packing is very efficient compared to the `struct' method, the code is hardly readable and it is impossible to reuse parts of it. It would be possible to extract the logic into functions, however the overheads introduced by the additional operations made it inferior to the technique we describe in this section.

We utilize Solidity's `Library' feature which allows us to define a set of methods which are possible to be applied on a datatype using the `using X for Y' syntax\footnote{This is similar to calling functions on struct's in Golang} 

The are two ways to implement functions in a Library:
\begin{enumerate}
    \item Internal: The library's bytecode is inlined to the main contract's code. This results in larger bytecode during deployment, however each of the contract's function are immediately jumping and returning to the Library's code, like any function. In this case, only the main contract gets deployed.
    \item Public: 
        \begin{enumerate}
            \item The library contract gets compiled and deployed
            \item The main contract gets compiled and has placeholder slots in the bytecode.
            \item The placeholder gets replaced by the deployed library's address
            \item Any function call that requires the library utilizes the `delegatecall' opcode.
        \end{enumerate}
\end{enumerate}

We provide a minimal code snippet which illustrates the syntax to use libraries. 

\begin{figure}[H]
    \centering
    \lstinputlisting[language=Solidity]{contracts/LibraryExample.sol}
    \label{fig:library}
    \caption{Example of `using X for Y' syntax to enhance operations done on datatypes}
\end{figure}

% Should insert placeholder and inlined bytecode? 

Libraries with public functions are deployed as standalone contracts to be used by contracts made by other developers. They often include generic functionality such as math operations\footnote{A popular Solidity Library is SafeMath which contains error-checked math operations}. Depending on the complexity of the contracts, this can be more efficient compared to using \textit{internal} functions. When \textit{public} is used, the DELEGATECALL opcode is used\footnote{Relays the message to the library while allowing it to execute in the sender's state}. When \textit{internal} is used, a function call is interpreted as a jump and thus is more efficient than the DELEGATECALL. 

That way, instead of having to deploy a new contract, developers can use an already deployed one. Due to the usage of DELEGATECALL, there is a tradeoff between the deployment cost of the contract and the extra costs when making function calls. We opt for the \textit{internal} approach because it requires less gas and since this is a specialized use-case it is not expected to be used by third-parties.

The final version is split in two files, the library which includes the API for setting and retrieving the character's traits, and the main contract which uses the library's high-level functions.

By utilizing the `using CharacterLib for bytes32' syntax we are able to write and retrieve the character's traits in a user-friendly manner.


The gas costs per function call with this method are: 
\input{tables/GameByteMaskingLib.sol_data.tex}

\subsection{Results}
It can be seen that in all cases the optimizer's first iteration creates significant gas savings. However, the more optimizer-runs were done, the more gas was spent during deployment. On the other hand, the cost of calling functions went down. Code in Solidity is either optimized for size, and thus costs less to deploy, or for runtime costs\cite{optimizer-tradeoff}. We proceed to compare the gas costs from each implementation while considering the advantages and disadvantages of each method. 

In Method 1 (\ref{table:tightpacking}) the optimizer is able to cut down deployment costs by 42\%, due to being able to pack all variables in a storage slot. In Method 2 (\ref{table:uint_masking_gas}), the optimization is done manually and has significant results both in deployment and in function costs. In Method 3 (\ref{table:byte_masking_gas}), although we follow the same pattern as in Method 2, we introduce a more verbose API which results in more complex operations being done at a lower level. This introduces slightly bigger deployment costs, and a negligible difference in gas costss for function calls. We consider this overhead to be worth it, since we export an API that is usable.  

Deciding how many times to run the optimizer requires estimating the expected usage of the smart contracts. Comparing the results from running the optimizer 1 and 500 times in Method 2, it can be seen that the deployment costs can increase by as much as 10\% while the savings for each function call are in the range of 0.7\%. When quantifying these percentages in gas, we conclude that if a function is going to be called \textit{enough}\footnote{Enough is not quantifiable and depends on the implementation. A developer should perform a similar analysis to the one we do in order to set their breakeven points.} times, then the contract which was compiled with more optimizer runs is more efficient in the long run. In addition, this shifts the costs towards the contract deployer rather than the users. Given the tradeoffs described above and the improved code readability and maintainability, we opt to use Method 3 in our implementations. 
% Depending on how many times the optimizer is run, there is a different breakeven point for making it worth running more than one times. Running the optimizer 100 times requires the `CreateCharacter' function to be called at least 24 times to make it worth it. % EXPLAIN BETTER THE QUANTIFICATION OF THE TRADEOFF PER FUNCTION CALL COMPARED TO DEPLOYMENT COSTS. Also, the initial cost comes on deployment from the deployer side 
% Even though 1300 gas at the price of 20gwei translates to 0.0000299 https://ethgasstation.info/calculatorTxV.php, this can be a considerable amount considering that a funciton call in a decentralized future might be called millions of times. 1 

% In addition, as we essentially do the optimization ourselves, the deployed bytecode is smaller. 
% This is not exactly intuitive, as it'd be expected that the solidity compiler is able to pack everything perfectly. this method is far more efficient. With this method we are able to store and fetch all the data in a very efficient way, which costs X\% gas less than the previous implementation. However, this method does not allow for a readable and maintainable interface. In order to export every functionality it is needed to convert the `uint' variables to bytes to perform the bit operations on functions. This creates undesired overhead and thus is avoided.

%We described a technique which relies on the compiler's optimizer to pack the data in a struct and do the gas savings, however is simpler and more elegant. The second and third technique are more complex and allow for further gas optimizations. The second technique is more efficient however lacks reusability and is less maintanable. On the other hand, utilizing libraries however we can export a user-friendly API for reusing our code for anyone who has the same use case as us. This technique will be utilized in the Design and implementation section.